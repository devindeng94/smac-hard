# 3s5z_vs_3s6z
CUDA_VISIBLE_DEVICES=0 python src/main.py --config=qmix --env-config=sc2 with env_args.map_name=3s5z_vs_3s6z runner=parallel batch_size_run=4 buffer_size=5000 t_max=10050000 epsilon_anneal_time=100000 batch_size=128 td_lambda=0.6
CUDA_VISIBLE_DEVICES=0 python src/main.py --config=qplex --env-config=sc2 with env_args.map_name=3s5z_vs_3s6z runner=parallel batch_size_run=4 buffer_size=5000 t_max=10050000 epsilon_anneal_time=100000 batch_size=128 td_lambda=0.6

# 6h_vs_8z
CUDA_VISIBLE_DEVICES=0 python src/main.py --config=qmix --env-config=sc2 with env_args.map_name=6h_vs_8z runner=parallel batch_size_run=8 buffer_size=5000 t_max=10050000 epsilon_anneal_time=500000 batch_size=128 td_lambda=0.3
CUDA_VISIBLE_DEVICES=0 python src/main.py --config=qplex --env-config=sc2 with env_args.map_name=6h_vs_8z runner=parallel batch_size_run=8 buffer_size=5000 t_max=10050000 epsilon_anneal_time=500000 batch_size=128 td_lambda=0.3

# other scenarios
CUDA_VISIBLE_DEVICES=0 python src/main.py --config=qmix --env-config=sc2 with env_args.map_name=8m_vs_9m runner=parallel batch_size_run=8 buffer_size=5000 t_max=10050000 epsilon_anneal_time=100000 batch_size=128 td_lambda=0.6
CUDA_VISIBLE_DEVICES=0 python src/main.py --config=qplex --env-config=sc2 with env_args.map_name=8m_vs_9m runner=parallel batch_size_run=8 buffer_size=5000 t_max=10050000 epsilon_anneal_time=100000 batch_size=128 td_lambda=0.6
